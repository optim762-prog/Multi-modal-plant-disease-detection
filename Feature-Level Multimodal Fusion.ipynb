{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "87323dec-5e90-411e-9f3e-2805d3f315a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "373ecc03-89e6-4cf8-8e85-4f1c79ceb810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique visual labels: [0 1 2]\n",
      "Unique meteo labels: [0 1]\n",
      "Filtered visual samples: 312 remain\n",
      "\n",
      "After mapping:\n",
      "  Visual samples: (312, 512)\n",
      "  Meteo matched:  (312, 6)\n",
      "\n",
      "✅ Final shapes:\n",
      "  Xv_train: (249, 512), Xm_train: (249, 6)\n",
      "  y_train:  (249,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load visual embeddings\n",
    "vis_data = np.load(\"visual_embeddings.npz\")\n",
    "X_visual = vis_data[\"X_visual\"]\n",
    "y = vis_data[\"y_visual\"]\n",
    "\n",
    "# Load meteorological embeddings\n",
    "met_data = np.load(\"meteo_embeddings.npz\")\n",
    "X_meteo = met_data[\"X_meteo\"]\n",
    "y_meteo = met_data[\"y_meteo\"]\n",
    "\n",
    "print(\"Unique visual labels:\", np.unique(y))\n",
    "print(\"Unique meteo labels:\", np.unique(y_meteo))\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Filter visual samples to keep only those with meteorological classes (0, 1)\n",
    "# -------------------------------------------------------\n",
    "mask_common = np.isin(y, np.unique(y_meteo))\n",
    "X_visual = X_visual[mask_common]\n",
    "y = y[mask_common]\n",
    "\n",
    "print(f\"Filtered visual samples: {X_visual.shape[0]} remain\")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Align samples by class\n",
    "# -------------------------------------------------------\n",
    "X_meteo_matched = []\n",
    "for cls in np.unique(y):\n",
    "    idx_vis = np.where(y == cls)[0]\n",
    "    idx_meteo = np.where(y_meteo == cls)[0]\n",
    "\n",
    "    if len(idx_meteo) == 0:\n",
    "        print(f\"⚠️ No meteo data for class {cls}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    n = len(idx_vis)\n",
    "    chosen_idx = np.random.choice(idx_meteo, size=n, replace=True)\n",
    "    X_meteo_matched.append(X_meteo[chosen_idx])\n",
    "\n",
    "X_meteo_matched = np.vstack(X_meteo_matched)\n",
    "\n",
    "print(\"\\nAfter mapping:\")\n",
    "print(f\"  Visual samples: {X_visual.shape}\")\n",
    "print(f\"  Meteo matched:  {X_meteo_matched.shape}\")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Normalize meteorological embeddings\n",
    "# -------------------------------------------------------\n",
    "scaler = StandardScaler()\n",
    "X_meteo_scaled = scaler.fit_transform(X_meteo_matched)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Train/test split (aligned and consistent)\n",
    "# -------------------------------------------------------\n",
    "Xv_train, Xv_test, Xm_train, Xm_test, y_train, y_test = train_test_split(\n",
    "    X_visual, X_meteo_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Final shapes:\")\n",
    "print(f\"  Xv_train: {Xv_train.shape}, Xm_train: {Xm_train.shape}\")\n",
    "print(f\"  y_train:  {y_train.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4955ded7-fa1a-440f-b984-869552527c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the Multimodal Fusion Network\n",
    "#This network:Projects each modality to a latent space\n",
    "#Concatenates them\n",
    "#Passes through dense layers with dropout and batch norm\n",
    "#Outputs multi-class predictions\n",
    "\n",
    "class MultimodalFusionNet(nn.Module):\n",
    "    def __init__(self, dim_vis=512, dim_met=6, fusion_dim=256, num_classes=3):\n",
    "        super(MultimodalFusionNet, self).__init__()\n",
    "\n",
    "        # Visual branch projection\n",
    "        self.vis_proj = nn.Sequential(\n",
    "            nn.Linear(dim_vis, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        # Meteorological branch projection\n",
    "        self.met_proj = nn.Sequential(\n",
    "            nn.Linear(dim_met, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        # Fusion and classification head\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(256 + 64, fusion_dim),\n",
    "            nn.BatchNorm1d(fusion_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(fusion_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_vis, x_met):\n",
    "        vis = self.vis_proj(x_vis)\n",
    "        met = self.met_proj(x_met)\n",
    "        fused = torch.cat((vis, met), dim=1)\n",
    "        out = self.fusion(fused)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca71f608-6cd5-48f4-95bf-c6061689de95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4df45fcc-2d8d-4774-a1d9-9fe2227bbceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data tensors\n",
    "Xv_train_t = torch.FloatTensor(Xv_train)\n",
    "Xm_train_t = torch.FloatTensor(Xm_train)\n",
    "y_train_t = torch.LongTensor(y_train)\n",
    "\n",
    "Xv_test_t = torch.FloatTensor(Xv_test)\n",
    "Xm_test_t = torch.FloatTensor(Xm_test)\n",
    "y_test_t = torch.LongTensor(y_test)\n",
    "\n",
    "# Model setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MultimodalFusionNet(dim_vis=Xv_train.shape[1],\n",
    "                            dim_met=Xm_train.shape[1],\n",
    "                            num_classes=len(np.unique(y_train))).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46ace9ec-50f1-4bba-a222-63e443e0b686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 - Loss: 0.5823\n",
      "Epoch 2/30 - Loss: 0.3714\n",
      "Epoch 3/30 - Loss: 0.2591\n",
      "Epoch 4/30 - Loss: 0.1982\n",
      "Epoch 5/30 - Loss: 0.1452\n",
      "Epoch 6/30 - Loss: 0.1360\n",
      "Epoch 7/30 - Loss: 0.1177\n",
      "Epoch 8/30 - Loss: 0.1048\n",
      "Epoch 9/30 - Loss: 0.0912\n",
      "Epoch 10/30 - Loss: 0.0821\n",
      "Epoch 11/30 - Loss: 0.0775\n",
      "Epoch 12/30 - Loss: 0.0605\n",
      "Epoch 13/30 - Loss: 0.0629\n",
      "Epoch 14/30 - Loss: 0.0523\n",
      "Epoch 15/30 - Loss: 0.0522\n",
      "Epoch 16/30 - Loss: 0.0471\n",
      "Epoch 17/30 - Loss: 0.0427\n",
      "Epoch 18/30 - Loss: 0.0432\n",
      "Epoch 19/30 - Loss: 0.0388\n",
      "Epoch 20/30 - Loss: 0.0314\n",
      "Epoch 21/30 - Loss: 0.0349\n",
      "Epoch 22/30 - Loss: 0.0292\n",
      "Epoch 23/30 - Loss: 0.0264\n",
      "Epoch 24/30 - Loss: 0.0291\n",
      "Epoch 25/30 - Loss: 0.0258\n",
      "Epoch 26/30 - Loss: 0.0266\n",
      "Epoch 27/30 - Loss: 0.0229\n",
      "Epoch 28/30 - Loss: 0.0224\n",
      "Epoch 29/30 - Loss: 0.0238\n",
      "Epoch 30/30 - Loss: 0.0197\n"
     ]
    }
   ],
   "source": [
    "#training loop\n",
    "epochs = 30\n",
    "batch_size = 32\n",
    "n_batches = len(Xv_train_t) // batch_size\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for i in range(n_batches):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        vis_batch = Xv_train_t[start:end].to(device)\n",
    "        met_batch = Xm_train_t[start:end].to(device)\n",
    "        y_batch = y_train_t[start:end].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(vis_batch, met_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {total_loss/n_batches:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f04689a9-abee-4438-8ef1-f4cc8f8d64b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 98.41%\n"
     ]
    }
   ],
   "source": [
    "#evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds = model(Xv_test_t.to(device), Xm_test_t.to(device))\n",
    "    predicted = torch.argmax(preds, dim=1).cpu().numpy()\n",
    "\n",
    "acc = np.mean(predicted == y_test)\n",
    "print(f\"Test Accuracy: {acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65348a4f-06b1-472e-be4b-30114a462b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "torch.save(model.state_dict(), \"multimodal_fusion_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d7b6a26-ecb9-44c3-836a-609259ff8ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available keys in meteo file: ['X_meteo', 'y_meteo']\n",
      "Visual: (464, 512), Meteo: (4020, 6)\n",
      "Unique visual labels: [0 1 2]\n",
      "Unique meteo labels: [0 1]\n"
     ]
    }
   ],
   "source": [
    "#With cross validation\n",
    "import numpy as np\n",
    "\n",
    "# --- Load pre-extracted embeddings ---\n",
    "vis_data = np.load(\"visual_embeddings.npz\")\n",
    "X_visual = vis_data[\"X_visual\"]\n",
    "y_visual = vis_data[\"y_visual\"]\n",
    "\n",
    "met_data = np.load(\"meteo_embeddings.npz\")\n",
    "print(\"Available keys in meteo file:\", met_data.files)\n",
    "X_meteo = met_data[\"X_meteo\"]\n",
    "y_meteo = met_data[\"y_meteo\"]\n",
    "\n",
    "print(f\"Visual: {X_visual.shape}, Meteo: {X_meteo.shape}\")\n",
    "print(f\"Unique visual labels: {np.unique(y_visual)}\")\n",
    "print(f\"Unique meteo labels: {np.unique(y_meteo)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05bb90bf-b4ab-41ea-babf-31813f24a721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Shapes after alignment:\n",
      "Visual: (464, 512)\n",
      "Meteo matched: (464, 6)\n",
      "Labels: (464,)\n"
     ]
    }
   ],
   "source": [
    "#Step 2 — Match meteorological data per image by class\n",
    "#We’ll randomly assign meteorological samples from the same class to each image.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create class-wise mapping for meteorological embeddings\n",
    "meteo_by_class = {c: np.where(y_meteo == c)[0] for c in np.unique(y_meteo)}\n",
    "\n",
    "X_meteo_matched = []\n",
    "\n",
    "for i, c in enumerate(y_visual):\n",
    "    if c in meteo_by_class and len(meteo_by_class[c]) > 0:\n",
    "        chosen_idx = np.random.choice(meteo_by_class[c])\n",
    "        X_meteo_matched.append(X_meteo[chosen_idx])\n",
    "    else:\n",
    "        # if no meteorological data for that class, sample from a random available one\n",
    "        random_class = np.random.choice(list(meteo_by_class.keys()))\n",
    "        chosen_idx = np.random.choice(meteo_by_class[random_class])\n",
    "        X_meteo_matched.append(X_meteo[chosen_idx])\n",
    "\n",
    "X_meteo_matched = np.array(X_meteo_matched)\n",
    "\n",
    "# --- Standardize ---\n",
    "scaler = StandardScaler()\n",
    "X_meteo_scaled = scaler.fit_transform(X_meteo_matched)\n",
    "\n",
    "print(\"✅ Shapes after alignment:\")\n",
    "print(\"Visual:\", X_visual.shape)\n",
    "print(\"Meteo matched:\", X_meteo_scaled.shape)\n",
    "print(\"Labels:\", y_visual.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3771339e-863f-4de3-8c8c-910c30650873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# Tracking all metrics across folds\n",
    "# ==============================================\n",
    "fold_metrics = {\n",
    "    \"accuracy\": [],\n",
    "    \"macro_f1\": [],\n",
    "    \"precision\": [],\n",
    "    \"recall\": [],\n",
    "    \"roc_auc_ovr\": [],\n",
    "    \"loss\": [],\n",
    "    \"inference_time_ms\": [],\n",
    "    \"model_size_mb\": []\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "340b3cf8-333c-456e-baf8-241780dbd486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiModalNet(nn.Module):\n",
    "    def __init__(self, visual_dim, meteo_dim, num_classes):\n",
    "        super(MultiModalNet, self).__init__()\n",
    "\n",
    "        # Visual branch\n",
    "        self.visual_branch = nn.Sequential(\n",
    "            nn.Linear(visual_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Meteorological branch\n",
    "        self.meteo_branch = nn.Sequential(\n",
    "            nn.Linear(meteo_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Fusion + classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128 + 32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_visual, x_meteo):\n",
    "        v = self.visual_branch(x_visual)\n",
    "        m = self.meteo_branch(x_meteo)\n",
    "        fused = torch.cat((v, m), dim=1)\n",
    "        out = self.classifier(fused)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3dfb50eb-b64e-4fce-8d70-8a94205401b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "#evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds = model(Xv_test_t.to(device), Xm_test_t.to(device))\n",
    "    predicted = torch.argmax(preds, dim=1).cpu().numpy()\n",
    "\n",
    "acc = np.mean(predicted == y_test)\n",
    "print(f\"Test Accuracy: {acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "39e50f3b-dfa3-4cc2-aab3-de47aba55b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold 1 / 10 =====\n",
      "Epoch 1/30 - Loss: 1.0779\n",
      "Epoch 2/30 - Loss: 0.9023\n",
      "Epoch 3/30 - Loss: 0.7627\n",
      "Epoch 4/30 - Loss: 0.6791\n",
      "Epoch 5/30 - Loss: 0.6333\n",
      "Epoch 6/30 - Loss: 0.6003\n",
      "Epoch 7/30 - Loss: 0.5516\n",
      "Epoch 8/30 - Loss: 0.4716\n",
      "Epoch 9/30 - Loss: 0.3881\n",
      "Epoch 10/30 - Loss: 0.3017\n",
      "Epoch 11/30 - Loss: 0.2220\n",
      "Epoch 12/30 - Loss: 0.1626\n",
      "Epoch 13/30 - Loss: 0.1205\n",
      "Epoch 14/30 - Loss: 0.0899\n",
      "Epoch 15/30 - Loss: 0.0676\n",
      "Epoch 16/30 - Loss: 0.0530\n",
      "Epoch 17/30 - Loss: 0.0426\n",
      "Epoch 18/30 - Loss: 0.0347\n",
      "Epoch 19/30 - Loss: 0.0287\n",
      "Epoch 20/30 - Loss: 0.0241\n",
      "Epoch 21/30 - Loss: 0.0203\n",
      "Epoch 22/30 - Loss: 0.0173\n",
      "Epoch 23/30 - Loss: 0.0148\n",
      "Epoch 24/30 - Loss: 0.0128\n",
      "Epoch 25/30 - Loss: 0.0110\n",
      "Epoch 26/30 - Loss: 0.0096\n",
      "Epoch 27/30 - Loss: 0.0084\n",
      "Epoch 28/30 - Loss: 0.0074\n",
      "Epoch 29/30 - Loss: 0.0065\n",
      "Epoch 30/30 - Loss: 0.0058\n",
      "Fold 1 Accuracy: 0.9688, ROC-AUC: 1.0000\n",
      "\n",
      "===== Fold 2 / 10 =====\n",
      "Epoch 1/30 - Loss: 1.1887\n",
      "Epoch 2/30 - Loss: 0.9751\n",
      "Epoch 3/30 - Loss: 0.7978\n",
      "Epoch 4/30 - Loss: 0.6540\n",
      "Epoch 5/30 - Loss: 0.5464\n",
      "Epoch 6/30 - Loss: 0.4804\n",
      "Epoch 7/30 - Loss: 0.4036\n",
      "Epoch 8/30 - Loss: 0.3073\n",
      "Epoch 9/30 - Loss: 0.2364\n",
      "Epoch 10/30 - Loss: 0.1705\n",
      "Epoch 11/30 - Loss: 0.1225\n",
      "Epoch 12/30 - Loss: 0.0917\n",
      "Epoch 13/30 - Loss: 0.0683\n",
      "Epoch 14/30 - Loss: 0.0526\n",
      "Epoch 15/30 - Loss: 0.0419\n",
      "Epoch 16/30 - Loss: 0.0340\n",
      "Epoch 17/30 - Loss: 0.0280\n",
      "Epoch 18/30 - Loss: 0.0235\n",
      "Epoch 19/30 - Loss: 0.0200\n",
      "Epoch 20/30 - Loss: 0.0172\n",
      "Epoch 21/30 - Loss: 0.0149\n",
      "Epoch 22/30 - Loss: 0.0130\n",
      "Epoch 23/30 - Loss: 0.0114\n",
      "Epoch 24/30 - Loss: 0.0100\n",
      "Epoch 25/30 - Loss: 0.0089\n",
      "Epoch 26/30 - Loss: 0.0079\n",
      "Epoch 27/30 - Loss: 0.0070\n",
      "Epoch 28/30 - Loss: 0.0063\n",
      "Epoch 29/30 - Loss: 0.0057\n",
      "Epoch 30/30 - Loss: 0.0051\n",
      "Fold 2 Accuracy: 1.0000, ROC-AUC: 1.0000\n",
      "\n",
      "===== Fold 3 / 10 =====\n",
      "Epoch 1/30 - Loss: 1.1880\n",
      "Epoch 2/30 - Loss: 0.9824\n",
      "Epoch 3/30 - Loss: 0.8609\n",
      "Epoch 4/30 - Loss: 0.7330\n",
      "Epoch 5/30 - Loss: 0.5944\n",
      "Epoch 6/30 - Loss: 0.4966\n",
      "Epoch 7/30 - Loss: 0.4111\n",
      "Epoch 8/30 - Loss: 0.3094\n",
      "Epoch 9/30 - Loss: 0.2310\n",
      "Epoch 10/30 - Loss: 0.1622\n",
      "Epoch 11/30 - Loss: 0.1170\n",
      "Epoch 12/30 - Loss: 0.0852\n",
      "Epoch 13/30 - Loss: 0.0631\n",
      "Epoch 14/30 - Loss: 0.0489\n",
      "Epoch 15/30 - Loss: 0.0389\n",
      "Epoch 16/30 - Loss: 0.0314\n",
      "Epoch 17/30 - Loss: 0.0260\n",
      "Epoch 18/30 - Loss: 0.0217\n",
      "Epoch 19/30 - Loss: 0.0184\n",
      "Epoch 20/30 - Loss: 0.0157\n",
      "Epoch 21/30 - Loss: 0.0135\n",
      "Epoch 22/30 - Loss: 0.0116\n",
      "Epoch 23/30 - Loss: 0.0101\n",
      "Epoch 24/30 - Loss: 0.0088\n",
      "Epoch 25/30 - Loss: 0.0077\n",
      "Epoch 26/30 - Loss: 0.0068\n",
      "Epoch 27/30 - Loss: 0.0060\n",
      "Epoch 28/30 - Loss: 0.0054\n",
      "Epoch 29/30 - Loss: 0.0048\n",
      "Epoch 30/30 - Loss: 0.0043\n",
      "Fold 3 Accuracy: 1.0000, ROC-AUC: 1.0000\n",
      "\n",
      "===== Fold 4 / 10 =====\n",
      "Epoch 1/30 - Loss: 1.1096\n",
      "Epoch 2/30 - Loss: 0.9179\n",
      "Epoch 3/30 - Loss: 0.7717\n",
      "Epoch 4/30 - Loss: 0.6931\n",
      "Epoch 5/30 - Loss: 0.6520\n",
      "Epoch 6/30 - Loss: 0.6281\n",
      "Epoch 7/30 - Loss: 0.5793\n",
      "Epoch 8/30 - Loss: 0.5232\n",
      "Epoch 9/30 - Loss: 0.4432\n",
      "Epoch 10/30 - Loss: 0.3502\n",
      "Epoch 11/30 - Loss: 0.2609\n",
      "Epoch 12/30 - Loss: 0.1843\n",
      "Epoch 13/30 - Loss: 0.1289\n",
      "Epoch 14/30 - Loss: 0.0907\n",
      "Epoch 15/30 - Loss: 0.0662\n",
      "Epoch 16/30 - Loss: 0.0507\n",
      "Epoch 17/30 - Loss: 0.0400\n",
      "Epoch 18/30 - Loss: 0.0326\n",
      "Epoch 19/30 - Loss: 0.0272\n",
      "Epoch 20/30 - Loss: 0.0229\n",
      "Epoch 21/30 - Loss: 0.0195\n",
      "Epoch 22/30 - Loss: 0.0166\n",
      "Epoch 23/30 - Loss: 0.0142\n",
      "Epoch 24/30 - Loss: 0.0123\n",
      "Epoch 25/30 - Loss: 0.0106\n",
      "Epoch 26/30 - Loss: 0.0092\n",
      "Epoch 27/30 - Loss: 0.0080\n",
      "Epoch 28/30 - Loss: 0.0070\n",
      "Epoch 29/30 - Loss: 0.0062\n",
      "Epoch 30/30 - Loss: 0.0054\n",
      "Fold 4 Accuracy: 1.0000, ROC-AUC: 1.0000\n",
      "\n",
      "===== Fold 5 / 10 =====\n",
      "Epoch 1/30 - Loss: 1.0759\n",
      "Epoch 2/30 - Loss: 0.8252\n",
      "Epoch 3/30 - Loss: 0.7067\n",
      "Epoch 4/30 - Loss: 0.6457\n",
      "Epoch 5/30 - Loss: 0.6059\n",
      "Epoch 6/30 - Loss: 0.5247\n",
      "Epoch 7/30 - Loss: 0.4376\n",
      "Epoch 8/30 - Loss: 0.3348\n",
      "Epoch 9/30 - Loss: 0.2462\n",
      "Epoch 10/30 - Loss: 0.1805\n",
      "Epoch 11/30 - Loss: 0.1294\n",
      "Epoch 12/30 - Loss: 0.0942\n",
      "Epoch 13/30 - Loss: 0.0708\n",
      "Epoch 14/30 - Loss: 0.0532\n",
      "Epoch 15/30 - Loss: 0.0416\n",
      "Epoch 16/30 - Loss: 0.0334\n",
      "Epoch 17/30 - Loss: 0.0269\n",
      "Epoch 18/30 - Loss: 0.0219\n",
      "Epoch 19/30 - Loss: 0.0183\n",
      "Epoch 20/30 - Loss: 0.0155\n",
      "Epoch 21/30 - Loss: 0.0131\n",
      "Epoch 22/30 - Loss: 0.0113\n",
      "Epoch 23/30 - Loss: 0.0097\n",
      "Epoch 24/30 - Loss: 0.0085\n",
      "Epoch 25/30 - Loss: 0.0074\n",
      "Epoch 26/30 - Loss: 0.0065\n",
      "Epoch 27/30 - Loss: 0.0058\n",
      "Epoch 28/30 - Loss: 0.0052\n",
      "Epoch 29/30 - Loss: 0.0046\n",
      "Epoch 30/30 - Loss: 0.0042\n",
      "Fold 5 Accuracy: 0.9677, ROC-AUC: 1.0000\n",
      "\n",
      "===== Fold 6 / 10 =====\n",
      "Epoch 1/30 - Loss: 1.1317\n",
      "Epoch 2/30 - Loss: 0.9173\n",
      "Epoch 3/30 - Loss: 0.7969\n",
      "Epoch 4/30 - Loss: 0.6561\n",
      "Epoch 5/30 - Loss: 0.5916\n",
      "Epoch 6/30 - Loss: 0.5349\n",
      "Epoch 7/30 - Loss: 0.4519\n",
      "Epoch 8/30 - Loss: 0.3787\n",
      "Epoch 9/30 - Loss: 0.2910\n",
      "Epoch 10/30 - Loss: 0.2137\n",
      "Epoch 11/30 - Loss: 0.1667\n",
      "Epoch 12/30 - Loss: 0.1274\n",
      "Epoch 13/30 - Loss: 0.0970\n",
      "Epoch 14/30 - Loss: 0.0765\n",
      "Epoch 15/30 - Loss: 0.0610\n",
      "Epoch 16/30 - Loss: 0.0489\n",
      "Epoch 17/30 - Loss: 0.0397\n",
      "Epoch 18/30 - Loss: 0.0324\n",
      "Epoch 19/30 - Loss: 0.0265\n",
      "Epoch 20/30 - Loss: 0.0217\n",
      "Epoch 21/30 - Loss: 0.0180\n",
      "Epoch 22/30 - Loss: 0.0150\n",
      "Epoch 23/30 - Loss: 0.0127\n",
      "Epoch 24/30 - Loss: 0.0108\n",
      "Epoch 25/30 - Loss: 0.0093\n",
      "Epoch 26/30 - Loss: 0.0081\n",
      "Epoch 27/30 - Loss: 0.0071\n",
      "Epoch 28/30 - Loss: 0.0063\n",
      "Epoch 29/30 - Loss: 0.0056\n",
      "Epoch 30/30 - Loss: 0.0050\n",
      "Fold 6 Accuracy: 0.9677, ROC-AUC: 0.9958\n",
      "\n",
      "===== Fold 7 / 10 =====\n",
      "Epoch 1/30 - Loss: 1.1437\n",
      "Epoch 2/30 - Loss: 1.0014\n",
      "Epoch 3/30 - Loss: 0.9006\n",
      "Epoch 4/30 - Loss: 0.7636\n",
      "Epoch 5/30 - Loss: 0.6060\n",
      "Epoch 6/30 - Loss: 0.4766\n",
      "Epoch 7/30 - Loss: 0.3834\n",
      "Epoch 8/30 - Loss: 0.2871\n",
      "Epoch 9/30 - Loss: 0.2134\n",
      "Epoch 10/30 - Loss: 0.1572\n",
      "Epoch 11/30 - Loss: 0.1171\n",
      "Epoch 12/30 - Loss: 0.0900\n",
      "Epoch 13/30 - Loss: 0.0695\n",
      "Epoch 14/30 - Loss: 0.0554\n",
      "Epoch 15/30 - Loss: 0.0450\n",
      "Epoch 16/30 - Loss: 0.0369\n",
      "Epoch 17/30 - Loss: 0.0308\n",
      "Epoch 18/30 - Loss: 0.0259\n",
      "Epoch 19/30 - Loss: 0.0220\n",
      "Epoch 20/30 - Loss: 0.0189\n",
      "Epoch 21/30 - Loss: 0.0164\n",
      "Epoch 22/30 - Loss: 0.0143\n",
      "Epoch 23/30 - Loss: 0.0126\n",
      "Epoch 24/30 - Loss: 0.0112\n",
      "Epoch 25/30 - Loss: 0.0099\n",
      "Epoch 26/30 - Loss: 0.0089\n",
      "Epoch 27/30 - Loss: 0.0080\n",
      "Epoch 28/30 - Loss: 0.0072\n",
      "Epoch 29/30 - Loss: 0.0065\n",
      "Epoch 30/30 - Loss: 0.0059\n",
      "Fold 7 Accuracy: 1.0000, ROC-AUC: 1.0000\n",
      "\n",
      "===== Fold 8 / 10 =====\n",
      "Epoch 1/30 - Loss: 1.1567\n",
      "Epoch 2/30 - Loss: 0.9382\n",
      "Epoch 3/30 - Loss: 0.7754\n",
      "Epoch 4/30 - Loss: 0.6408\n",
      "Epoch 5/30 - Loss: 0.5729\n",
      "Epoch 6/30 - Loss: 0.5137\n",
      "Epoch 7/30 - Loss: 0.4431\n",
      "Epoch 8/30 - Loss: 0.3530\n",
      "Epoch 9/30 - Loss: 0.2724\n",
      "Epoch 10/30 - Loss: 0.2027\n",
      "Epoch 11/30 - Loss: 0.1442\n",
      "Epoch 12/30 - Loss: 0.1049\n",
      "Epoch 13/30 - Loss: 0.0768\n",
      "Epoch 14/30 - Loss: 0.0579\n",
      "Epoch 15/30 - Loss: 0.0455\n",
      "Epoch 16/30 - Loss: 0.0366\n",
      "Epoch 17/30 - Loss: 0.0301\n",
      "Epoch 18/30 - Loss: 0.0253\n",
      "Epoch 19/30 - Loss: 0.0215\n",
      "Epoch 20/30 - Loss: 0.0184\n",
      "Epoch 21/30 - Loss: 0.0159\n",
      "Epoch 22/30 - Loss: 0.0138\n",
      "Epoch 23/30 - Loss: 0.0121\n",
      "Epoch 24/30 - Loss: 0.0106\n",
      "Epoch 25/30 - Loss: 0.0093\n",
      "Epoch 26/30 - Loss: 0.0083\n",
      "Epoch 27/30 - Loss: 0.0073\n",
      "Epoch 28/30 - Loss: 0.0065\n",
      "Epoch 29/30 - Loss: 0.0059\n",
      "Epoch 30/30 - Loss: 0.0053\n",
      "Fold 8 Accuracy: 1.0000, ROC-AUC: 1.0000\n",
      "\n",
      "===== Fold 9 / 10 =====\n",
      "Epoch 1/30 - Loss: 1.0776\n",
      "Epoch 2/30 - Loss: 0.9367\n",
      "Epoch 3/30 - Loss: 0.8612\n",
      "Epoch 4/30 - Loss: 0.7625\n",
      "Epoch 5/30 - Loss: 0.6338\n",
      "Epoch 6/30 - Loss: 0.5162\n",
      "Epoch 7/30 - Loss: 0.4131\n",
      "Epoch 8/30 - Loss: 0.3043\n",
      "Epoch 9/30 - Loss: 0.2209\n",
      "Epoch 10/30 - Loss: 0.1582\n",
      "Epoch 11/30 - Loss: 0.1114\n",
      "Epoch 12/30 - Loss: 0.0825\n",
      "Epoch 13/30 - Loss: 0.0626\n",
      "Epoch 14/30 - Loss: 0.0476\n",
      "Epoch 15/30 - Loss: 0.0375\n",
      "Epoch 16/30 - Loss: 0.0297\n",
      "Epoch 17/30 - Loss: 0.0238\n",
      "Epoch 18/30 - Loss: 0.0194\n",
      "Epoch 19/30 - Loss: 0.0160\n",
      "Epoch 20/30 - Loss: 0.0133\n",
      "Epoch 21/30 - Loss: 0.0113\n",
      "Epoch 22/30 - Loss: 0.0097\n",
      "Epoch 23/30 - Loss: 0.0084\n",
      "Epoch 24/30 - Loss: 0.0073\n",
      "Epoch 25/30 - Loss: 0.0065\n",
      "Epoch 26/30 - Loss: 0.0057\n",
      "Epoch 27/30 - Loss: 0.0051\n",
      "Epoch 28/30 - Loss: 0.0045\n",
      "Epoch 29/30 - Loss: 0.0041\n",
      "Epoch 30/30 - Loss: 0.0036\n",
      "Fold 9 Accuracy: 0.9677, ROC-AUC: 1.0000\n",
      "\n",
      "===== Fold 10 / 10 =====\n",
      "Epoch 1/30 - Loss: 1.1098\n",
      "Epoch 2/30 - Loss: 0.8496\n",
      "Epoch 3/30 - Loss: 0.7062\n",
      "Epoch 4/30 - Loss: 0.6134\n",
      "Epoch 5/30 - Loss: 0.5621\n",
      "Epoch 6/30 - Loss: 0.4798\n",
      "Epoch 7/30 - Loss: 0.3782\n",
      "Epoch 8/30 - Loss: 0.2903\n",
      "Epoch 9/30 - Loss: 0.2198\n",
      "Epoch 10/30 - Loss: 0.1652\n",
      "Epoch 11/30 - Loss: 0.1260\n",
      "Epoch 12/30 - Loss: 0.0983\n",
      "Epoch 13/30 - Loss: 0.0773\n",
      "Epoch 14/30 - Loss: 0.0619\n",
      "Epoch 15/30 - Loss: 0.0505\n",
      "Epoch 16/30 - Loss: 0.0417\n",
      "Epoch 17/30 - Loss: 0.0348\n",
      "Epoch 18/30 - Loss: 0.0292\n",
      "Epoch 19/30 - Loss: 0.0239\n",
      "Epoch 20/30 - Loss: 0.0208\n",
      "Epoch 21/30 - Loss: 0.0174\n",
      "Epoch 22/30 - Loss: 0.0145\n",
      "Epoch 23/30 - Loss: 0.0127\n",
      "Epoch 24/30 - Loss: 0.0110\n",
      "Epoch 25/30 - Loss: 0.0095\n",
      "Epoch 26/30 - Loss: 0.0083\n",
      "Epoch 27/30 - Loss: 0.0073\n",
      "Epoch 28/30 - Loss: 0.0064\n",
      "Epoch 29/30 - Loss: 0.0057\n",
      "Epoch 30/30 - Loss: 0.0051\n",
      "Fold 10 Accuracy: 1.0000, ROC-AUC: 1.0000\n",
      "\n",
      "===== 10-Fold Cross-Validation Results =====\n",
      "accuracy: 0.9872 ± 0.0157\n",
      "macro_f1: 0.9872 ± 0.0157\n",
      "precision: 0.9873 ± 0.0156\n",
      "recall: 0.9879 ± 0.0149\n",
      "roc_auc_ovr: 0.9996 ± 0.0012\n",
      "inference_time_ms: 0.0390 ± 0.0810\n",
      "model_size_mb: 0.3140 ± 0.0000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, roc_auc_score\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "# ===============================\n",
    "# Assume these are already defined:\n",
    "# X_visual, X_meteo_scaled, y_visual\n",
    "# MultiModalNet class\n",
    "# ===============================\n",
    "\n",
    "Xv_all = X_visual        # Aligned visual embeddings\n",
    "Xm_all = X_meteo_scaled  # Aligned meteorological embeddings\n",
    "y_all = y_visual         \n",
    "\n",
    "# Convert to tensors\n",
    "Xv_all_t = torch.tensor(Xv_all, dtype=torch.float32)\n",
    "Xm_all_t = torch.tensor(Xm_all, dtype=torch.float32)\n",
    "y_all_t = torch.tensor(y_all, dtype=torch.long)\n",
    "\n",
    "# K-Fold setup\n",
    "n_splits = 10\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Training config\n",
    "epochs = 30\n",
    "batch_size = 32\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Metrics storage\n",
    "metrics = {\n",
    "    \"accuracy\": [],\n",
    "    \"macro_f1\": [],\n",
    "    \"precision\": [],\n",
    "    \"recall\": [],\n",
    "    \"roc_auc_ovr\": [],\n",
    "    \"confusion_matrices\": [],\n",
    "    \"inference_time_ms\": [],\n",
    "    \"model_size_mb\": [],\n",
    "}\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(Xv_all)):\n",
    "    print(f\"\\n===== Fold {fold+1} / {n_splits} =====\")\n",
    "\n",
    "    # Split tensors\n",
    "    Xv_train_t, Xv_val_t = Xv_all_t[train_idx], Xv_all_t[val_idx]\n",
    "    Xm_train_t, Xm_val_t = Xm_all_t[train_idx], Xm_all_t[val_idx]\n",
    "    y_train_t, y_val_t = y_all_t[train_idx], y_all_t[val_idx]\n",
    "\n",
    "    # Initialize model for this fold\n",
    "    model = MultiModalNet(Xv_all.shape[1], Xm_all.shape[1], num_classes=len(np.unique(y_all)))\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # --- Training loop ---\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        n_batches = len(Xv_train_t) // batch_size\n",
    "        for i in range(n_batches):\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "            vis_batch = Xv_train_t[start:end].to(device)\n",
    "            met_batch = Xm_train_t[start:end].to(device)\n",
    "            y_batch = y_train_t[start:end].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(vis_batch, met_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / n_batches\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # --- Evaluation ---\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        start_time = time.time()\n",
    "        outputs = model(Xv_val_t.to(device), Xm_val_t.to(device))\n",
    "        inference_time = (time.time() - start_time) / len(Xv_val_t) * 1000  # ms/sample\n",
    "\n",
    "        y_pred_classes = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "        y_true = y_val_t.cpu().numpy()\n",
    "\n",
    "    # Metrics computation\n",
    "    acc = accuracy_score(y_true, y_pred_classes)\n",
    "    macro_f1 = f1_score(y_true, y_pred_classes, average=\"macro\")\n",
    "    precision = precision_score(y_true, y_pred_classes, average=\"macro\", zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred_classes, average=\"macro\", zero_division=0)\n",
    "    cm = confusion_matrix(y_true, y_pred_classes)\n",
    "\n",
    "    # ROC-AUC robust computation: only for present classes\n",
    "    y_probs = torch.softmax(outputs, dim=1).cpu().numpy()\n",
    "    present_classes = np.unique(y_true)\n",
    "    roc_auc_per_class = []\n",
    "    for cls in present_classes:\n",
    "        y_true_bin = (y_true == cls).astype(int)\n",
    "        roc_auc_per_class.append(roc_auc_score(y_true_bin, y_probs[:, cls]))\n",
    "    roc_auc = np.mean(roc_auc_per_class)\n",
    "\n",
    "    # Model size in MB\n",
    "    torch.save(model.state_dict(), \"temp_model.pth\")\n",
    "    model_size_mb = os.path.getsize(\"temp_model.pth\") / 1e6\n",
    "    os.remove(\"temp_model.pth\")\n",
    "\n",
    "    # Store metrics\n",
    "    metrics[\"accuracy\"].append(acc)\n",
    "    metrics[\"macro_f1\"].append(macro_f1)\n",
    "    metrics[\"precision\"].append(precision)\n",
    "    metrics[\"recall\"].append(recall)\n",
    "    metrics[\"roc_auc_ovr\"].append(roc_auc)\n",
    "    metrics[\"confusion_matrices\"].append(cm)\n",
    "    metrics[\"inference_time_ms\"].append(inference_time)\n",
    "    metrics[\"model_size_mb\"].append(model_size_mb)\n",
    "\n",
    "    print(f\"Fold {fold+1} Accuracy: {acc:.4f}, ROC-AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# --- Final summary ---\n",
    "print(\"\\n===== 10-Fold Cross-Validation Results =====\")\n",
    "for k, v in metrics.items():\n",
    "    if k != \"confusion_matrices\":\n",
    "        print(f\"{k}: {np.mean(v):.4f} ± {np.std(v):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
